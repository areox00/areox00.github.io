---
layout: post
title: "Making synthesizer in C++ and SDL2"
---

As far as my interest in music and DSP grows I want to create my own synthesizer, so here we go.

---

## Hello world!
```
#include <SDL2/SDL.h>

int main()
{
    SDL_Init(SDL_INIT_AUDIO);

    SDL_AudioSpec spec;
    spec.freq = 48000;
    spec.channels = 1;
    spec.format = AUDIO_F32SYS;
    spec.samples = 256;
    spec.callback = [](void *data, Uint8 *bytes, int len) {
        // TODO
    };

    auto device = SDL_OpenAudioDevice(nullptr, 0, &spec, &spec, 0);
    SDL_PauseAudioDevice(device, 0);
}
```
Above code creates audio spec - struct that contains information about audio such as sampling rate, sample format, buffer size and so on.

Why 48kHz and f32? Well that's topic for different post but briefly: 48kHz sampling rate allows us to represent digitally highest possible frequency that human can hear (around 20kHz).
Floats as sample format are best option for processing sound (for exporting audio 16 bit signed integers are used),
signed integers are mapped to -1.0 - 1.0 whereas floats can exceed that range (in signed integers clipping and precision loss will occur).

Ah, and buffer size, 256 seems to be sensible (smaller buffer size reduces latency, however at some point problems with performance might appear).

There are two ways of playing sound, either you use callback function or [SDL_QueueAudio](https://wiki.libsdl.org/SDL2/SDL_QueueAudio) function.
With callback function you might create data races because audio works on another thread, tbh they are quite harmless, if you wish you can omit them.
I'll feed audio device by callback.

And next we [open audio device](https://wiki.libsdl.org/SDL2/SDL_OpenAudioDevice) and [unpause it](https://wiki.libsdl.org/SDL2/SDL_PauseAudioDevice) cuz it's paused by default.

## Playing waveforms

From now we can start making synthesizer, we'll start by generating waveform. Waveform is just graph which represent sound.

### Example of some waveforms
![Example of some waveforms](/images/synth/waveforms.webp)


Let's create a synthesizer class.

```
class Synthesizer {
private:
    float m_timestep = 0;
    float m_phasestep = 0;
    float m_phase = 0;
    float m_freq;
    bool m_playing = false;
public:
    Synthesizer(int sample_rate)
    {
        m_timestep = 1.f / sample_rate;
    }

    void synthesize(float *buffer, size_t buffer_size)
    {
        for (size_t i = 0; i < buffer_size; i++) {
            if (!m_playing && m_phase < 0.001f) {
                return;
            }

            buffer[i] = sinf(m_phase * 2 * M_PI) * 0.5f;
            m_phase += m_phasestep;
            m_phase = fmodf(m_phase, 1.f);
        }
    }

    void play(float freq)
    {
        m_phasestep = m_timestep * freq;
        m_freq = freq;
        m_playing = true;
    }

    void stop()
    {
        m_playing = false;
    }
};
```

Sample rate tells us how many samples are in one second, if we divide 1 second by it we get interval by which we can move in time, but there is also one thing - phase.

`Phase` tells us how much fraction of waveform cycle we've done.

If it's 0 then we're at the beggining of wave cycle.

If it's 0.5 then we're at the middle of wave cycle.

And so on...

And of course we repeat this by `fmodf(m_phase, 1.f)`.

To calculate current phase we add to phase phase step.

Phase step is similar to time step but it refers to cycle not time in general.

To calculate phase step we just multiply it by frequency.

Synthesize method takes buffer and writes into it appropriate samples.

One thing might be unclear: in `if (!m_playing && m_phase < 0.001f)` what does `m_phase < 0.001f` do?

Without this after releasing key our waveform might cut in some unexpected position which will result in irritating to ear sound.

### This will happen
![oh no](/images/synth/ohno.webp)

Therefore we use `m_phase < 0.001f` to wait till waveform ends it's cycle.

### Neat!
![Neat!](/images/synth/neat.webp)

We can now play sine wave but we need one more thing - emulating piano on keyboard.

### Mapping piano keys to keyboard keys
![Mapping piano keys to keyboard keys](/images/synth/keys.webp)

We will try to recreate piano layout. [This formula](https://pages.mtu.edu/~suits/NoteFreqCalcs.html) will be helpful.

Let's start by putting all keys into lookup table, this approach is very flexible and will allow to easily extend keys and create custom bindings.

```
std::unordered_map<SDL_Keycode, int> piano_keys = {
    {SDLK_z, 0},
    {SDLK_s, 1},
    {SDLK_x, 2},
    {SDLK_d, 3},
    {SDLK_c, 4},
    {SDLK_v, 5},
    {SDLK_g, 6},
    {SDLK_b, 7},
    {SDLK_h, 8},
    {SDLK_n, 9},
    {SDLK_j, 10},
    {SDLK_m, 11},
};
```

Now create a function that takes key and returns proper frequency

```
float get_freq(SDL_Keycode key)
{
    return 440.f * powf(2.f, piano_keys[key] / 12.f);
}
```

We just take key and using [this formula](https://pages.mtu.edu/~suits/NoteFreqCalcs.html) convert it into frequency.

Also create a window to allow (simplifying) OS send pressed keys to program event queue.

In our event loop:
```
SDL_Keycode pressed_key;
while (running) {
...
    while (SDL_PollEvent(&event)) {
        switch(event.type) {
            case SDL_QUIT:
                running = false;
                break;

            case SDL_KEYDOWN:
                pressed_key = event.key.keysym.sym;
                if (piano_keys.count(pressed_key)) {
                    synth.play(get_freq(pressed_key));
                }
                break;
            case SDL_KEYUP:
                if (event.key.keysym.sym == pressed_key) {
                    synth.stop();
                }
                break;

            default:
                break;
        }
    }
...
```

We check for `SDL_KEYDOWN` event and if key is pressed we signal to play audio and set adequate frequency based on pressed key.

Why store pressed key?

Well if you won't check for it, in `SDL_KEYUP` you could easily interrupt playing by releasing old pressed key.

----

## Final code
```
#include <SDL2/SDL.h>
#include <cmath>
#include <unordered_map>

class Synthesizer {
private:
    float m_timestep = 0;
    float m_phasestep = 0;
    float m_phase = 0;
    float m_freq;
    bool m_playing = false;
public:
    Synthesizer(int sample_rate)
    {
        m_timestep = 1.f / sample_rate;
    }

    void synthesize(float *buffer, size_t buffer_size)
    {
        for (size_t i = 0; i < buffer_size; i++) {
            if (!m_playing && m_phase < 0.001f) {
                return;
            }

            buffer[i] = sinf(m_phase * 2 * M_PI) * 0.5f;
            m_phase += m_phasestep;
            m_phase = fmodf(m_phase, 1.f);
        }
    }

    void play(float freq)
    {
        m_phasestep = m_timestep * freq;
        m_freq = freq;
        m_playing = true;
    }

    void stop()
    {
        m_playing = false;
    }
};

std::unordered_map<SDL_Keycode, int> piano_keys = {
    {SDLK_z, 0},
    {SDLK_s, 1},
    {SDLK_x, 2},
    {SDLK_d, 3},
    {SDLK_c, 4},
    {SDLK_v, 5},
    {SDLK_g, 6},
    {SDLK_b, 7},
    {SDLK_h, 8},
    {SDLK_n, 9},
    {SDLK_j, 10},
    {SDLK_m, 11},
};

float get_freq(SDL_Keycode key)
{
    return 440.f * powf(2.f, piano_keys[key] / 12.f);
}

int main()
{
    SDL_Init(SDL_INIT_AUDIO);

    Synthesizer synth(48000);

    SDL_AudioSpec spec;
    spec.freq = 48000;
    spec.channels = 1;
    spec.format = AUDIO_F32SYS;
    spec.samples = 256;
    spec.callback = [](void *userdata, Uint8 *bytes, int len) {
        Synthesizer *synth = (Synthesizer *)userdata;
        memset(bytes, 0, len);
        synth->synthesize(
            (float *)bytes,
            len / sizeof(float));
    };
    spec.userdata = &synth;

    SDL_AudioDeviceID device = SDL_OpenAudioDevice(nullptr, 0, &spec, &spec, 0);
    SDL_PauseAudioDevice(device, 0);

    SDL_Window *window = SDL_CreateWindow("synth", 0, 0, 800, 600, 0);
    SDL_Surface *surface = SDL_GetWindowSurface(window);
    SDL_Event event;

    bool running = true;

    // 16ms of latency
    const int lag = 1000 / 60;
    Uint64 start, elapsed;

    SDL_Keycode pressed_key;

    while (running) {
        start = SDL_GetTicks64();
        while (SDL_PollEvent(&event)) {
            switch(event.type) {
                case SDL_QUIT:
                    running = false;
                    break;

                case SDL_KEYDOWN:
                    pressed_key = event.key.keysym.sym;
                    if (piano_keys.count(pressed_key)) {
                        synth.play(get_freq(pressed_key));
                    }
                    break;
                case SDL_KEYUP:
                    if (event.key.keysym.sym == pressed_key) {
                        synth.stop();
                    }
                    break;

                default:
                    break;
            }
        }

        SDL_UpdateWindowSurface(window);

        elapsed = SDL_GetTicks() - start;
        if (lag > elapsed) {
            SDL_Delay(lag - elapsed);
        }
    }
}
```

And for now this implementation is monophonic, it means that only single key can be played.

Other important thing is that I didn't implemented any anti-aliasing filter so aliasing will occur, I will take care of that later.

So... it's all for now I guess, in the next parts we will implement some visualizers, ADSR, complex waveforms and polyphony.

Bye!
